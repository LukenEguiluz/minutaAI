# MinutaAI - Transcripci√≥n de Audio/Video

Una aplicaci√≥n web completa para transcripci√≥n autom√°tica de archivos de audio y video usando Whisper AI.

## üöÄ Caracter√≠sticas

- **Soporte m√∫ltiple de formatos**: Audio (MP3, WAV, M4A, AAC, OGG, FLAC) y Video (MP4, AVI, MOV, MKV, WEBM)
- **Divisi√≥n autom√°tica**: Divide el audio en bloques de 30 segundos para mejor procesamiento
- **Transcripci√≥n inteligente**: Usa Whisper AI para transcripci√≥n precisa
- **Interfaz moderna**: Frontend responsive y f√°cil de usar
- **Descarga autom√°tica**: Genera archivo TXT con la transcripci√≥n completa
- **Validaciones**: Verifica formato y tama√±o de archivos

## üìã Requisitos

- Python 3.8 o superior
- FFmpeg (para procesamiento de video)

### Instalaci√≥n de FFmpeg

**Opci√≥n 1: Instalaci√≥n autom√°tica**
```bash
python install_ffmpeg.py
```

**Opci√≥n 2: Instalaci√≥n manual**

**Windows:**
```bash
# Usando chocolatey
choco install ffmpeg

# O usando winget
winget install FFmpeg

# O descargar desde https://ffmpeg.org/download.html
```

**macOS:**
```bash
brew install ffmpeg
```

**Linux (Ubuntu/Debian):**
```bash
sudo apt update
sudo apt install ffmpeg
```

## üõ†Ô∏è Instalaci√≥n

### Opci√≥n 1: Instalaci√≥n Autom√°tica (Recomendada)

1. **Clonar o descargar el proyecto**
```bash
git clone <repository-url>
cd MinutaAI
```

2. **Ejecutar script de instalaci√≥n**
```bash
python install.py
```

### Opci√≥n 2: Instalaci√≥n Manual

Si la instalaci√≥n autom√°tica falla, usa el script manual:

```bash
python install_manual.py
```

### Opci√≥n 3: Instalaci√≥n Manual Paso a Paso

1. **Crear entorno virtual**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

2. **Instalar dependencias b√°sicas**
```bash
pip install flask==2.3.3 flask-cors==4.0.0 werkzeug==2.3.7 python-dotenv==1.0.0 requests
```

3. **Instalar dependencias de audio**
```bash
pip install numpy moviepy==1.0.3
```

4. **Instalar Whisper (prueba una de estas opciones)**
```bash
pip install openai-whisper
# o
pip install openai-whisper==20231117
# o
pip install git+https://github.com/openai/whisper.git
```

## üê≥ Docker (hostear en PC / VPN / dominio)

Para ejecutar MinutaAI en un contenedor Docker y exponerlo en tu red o VPN:

```bash
# Construir y ejecutar
docker compose up -d

# Ver logs
docker compose logs -f minutaai
```

La app estar√° disponible en `http://localhost:5000` y escucha en todas las interfaces (`0.0.0.0`), por lo que es accesible desde otros dispositivos en tu red local y desde tu VPN.

**Puentear a un dominio**: Usa un t√∫nel (Cloudflare Tunnel, ngrok, Tailscale) o un reverse proxy (nginx, Caddy) en tu PC para apuntar tu dominio al puerto 5000. Ver [DOCKER.md](DOCKER.md) para m√°s detalles.

## üöÄ Uso

### Verificar Instalaci√≥n

Antes de usar la aplicaci√≥n, verifica que todo est√© funcionando:

```bash
# Prueba b√°sica (sin Whisper)
python test_basic.py

# Prueba de FFmpeg
python test_ffmpeg.py

# Prueba completa (con Whisper)
python test_example.py
```

### Ejecutar la Aplicaci√≥n

**Opci√≥n 1: Inicio r√°pido (recomendado)**
```bash
python quick_start.py
```

**Opci√≥n 2: Inicio est√°ndar**
```bash
python app.py
# o
python run.py
```

2. **Abrir en el navegador**
```
http://localhost:5000
```

3. **Usar la aplicaci√≥n**
   - Arrastra un archivo de audio o video al √°rea de subida
   - O haz clic para seleccionar un archivo
   - Haz clic en "Transcribir"
   - Espera a que se complete el procesamiento
   - Descarga el archivo TXT con la transcripci√≥n

## üìÅ Estructura del Proyecto

```
MinutaAI/
‚îú‚îÄ‚îÄ app.py                 # Backend Flask
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html        # Frontend
‚îú‚îÄ‚îÄ uploads/              # Archivos subidos (se crea autom√°ticamente)
‚îî‚îÄ‚îÄ README.md            # Este archivo
```

## üîß Configuraci√≥n

### L√≠mites de archivo
- Tama√±o m√°ximo: 500MB
- Formatos soportados: Ver lista en la interfaz web

### Modelo Whisper
- Por defecto usa el modelo "base" de Whisper
- Puedes cambiar el modelo en `app.py` l√≠nea 108:
```python
model = whisper.load_model("base")  # Opciones: "tiny", "base", "small", "medium", "large"
```

## üêõ Soluci√≥n de Problemas

### Error: "No se puede conectar con el servidor"
- Verifica que el servidor est√© ejecut√°ndose en `http://localhost:5000`
- Revisa que no haya otro proceso usando el puerto 5000

### Error: "FFmpeg no encontrado"
- Instala FFmpeg siguiendo las instrucciones de arriba
- Aseg√∫rate de que FFmpeg est√© en el PATH del sistema

### Error: "Modelo Whisper no encontrado"
- La primera vez que ejecutes la aplicaci√≥n, descargar√° autom√°ticamente el modelo
- Aseg√∫rate de tener conexi√≥n a internet

### Error: "Error instalando Whisper"
- **Problema**: Whisper puede tener problemas de compatibilidad con Python 3.13
- **Soluci√≥n 1**: Usar Python 3.11 o 3.12
- **Soluci√≥n 2**: Instalar Whisper manualmente:
  ```bash
  pip install openai-whisper
  ```
- **Soluci√≥n 3**: Usar conda:
  ```bash
  conda install -c conda-forge openai-whisper
  ```
- **Soluci√≥n 4**: Instalar desde git:
  ```bash
  pip install git+https://github.com/openai/whisper.git
  ```

### Error: "Archivo demasiado grande"
- El l√≠mite es 500MB por archivo
- Considera dividir archivos muy grandes

## üìä Rendimiento

- **Tiempo de procesamiento**: Depende del tama√±o del archivo y la duraci√≥n
- **Memoria**: El modelo Whisper requiere aproximadamente 1GB de RAM
- **CPU**: Procesamiento intensivo, recomendado usar CPU moderna

## üîí Seguridad

- Los archivos subidos se almacenan temporalmente
- Se limpian autom√°ticamente despu√©s del procesamiento
- No se almacenan transcripciones permanentemente

## ü§ù Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## üôè Agradecimientos

- [OpenAI Whisper](https://github.com/openai/whisper) - Modelo de transcripci√≥n
- [Flask](https://flask.palletsprojects.com/) - Framework web
- [MoviePy](https://zulko.github.io/moviepy/) - Procesamiento de video
- [Pydub](https://github.com/jiaaro/pydub) - Procesamiento de audio 